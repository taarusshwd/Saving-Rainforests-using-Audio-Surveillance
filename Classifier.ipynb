{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Classifier.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCJYba4tg1zF",
        "outputId": "5f5a0b6b-2489-4f87-bb30-6e304281d5d9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_F9j_LUgrax"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzygD21Dgwkj"
      },
      "source": [
        "samples = []\n",
        "labels = []\n",
        "images_folder = \"/content/drive/MyDrive/images/\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgzpZkK3iCTm",
        "outputId": "d9e9ddce-9314-4b42-b60c-bdccb1acc23e"
      },
      "source": [
        "for image in os.listdir(images_folder):\n",
        "    samples.append(tf.keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(images_folder+image, target_size=(100, 100))))\n",
        "    if \"normal\" in image:\n",
        "        labels.append((0))\n",
        "    else:\n",
        "        labels.append((1))\n",
        "samples = np.array(samples)\n",
        "labels = np.array(labels)\n",
        "eval_x, eval_y = samples[-100:], labels[-100:]\n",
        "print(samples.shape, labels.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 100, 100, 3) (2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0h8TneKiHdc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPZm5-Jgi76s"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(samples[:-100], labels[:-100], test_size=0.2, random_state=31)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHGn3y7VjFM7",
        "outputId": "bf9785b7-8207-4a8f-93f8-60aec3720a08"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), input_shape=(100, 100, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "print(model.summary())\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=150,\n",
        "          validation_data=(x_test, y_test),\n",
        "         verbose=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 98, 98, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 49, 49, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 49, 49, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 47, 47, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16928)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 16929     \n",
            "=================================================================\n",
            "Total params: 22,017\n",
            "Trainable params: 22,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "48/48 [==============================] - 11s 210ms/step - loss: 46.7037 - accuracy: 0.5377 - val_loss: 0.6892 - val_accuracy: 0.5474\n",
            "Epoch 2/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 1.6161 - accuracy: 0.5363 - val_loss: 0.6948 - val_accuracy: 0.4553\n",
            "Epoch 3/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.9813 - accuracy: 0.5121 - val_loss: 0.6911 - val_accuracy: 0.4579\n",
            "Epoch 4/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.7782 - accuracy: 0.5310 - val_loss: 0.6876 - val_accuracy: 0.4737\n",
            "Epoch 5/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.7469 - accuracy: 0.5544 - val_loss: 0.6875 - val_accuracy: 0.4711\n",
            "Epoch 6/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.7469 - accuracy: 0.5152 - val_loss: 0.6869 - val_accuracy: 0.4816\n",
            "Epoch 7/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.6956 - accuracy: 0.5500 - val_loss: 0.6867 - val_accuracy: 0.4816\n",
            "Epoch 8/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.7061 - accuracy: 0.5306 - val_loss: 0.6850 - val_accuracy: 0.4868\n",
            "Epoch 9/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.6858 - accuracy: 0.5679 - val_loss: 0.6840 - val_accuracy: 0.4921\n",
            "Epoch 10/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.6940 - accuracy: 0.5276 - val_loss: 0.6866 - val_accuracy: 0.4895\n",
            "Epoch 11/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.6888 - accuracy: 0.5371 - val_loss: 0.6857 - val_accuracy: 0.4868\n",
            "Epoch 12/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.6961 - accuracy: 0.5255 - val_loss: 0.6845 - val_accuracy: 0.4868\n",
            "Epoch 13/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.6805 - accuracy: 0.5508 - val_loss: 0.6838 - val_accuracy: 0.4868\n",
            "Epoch 14/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.6673 - accuracy: 0.5580 - val_loss: 0.6834 - val_accuracy: 0.4947\n",
            "Epoch 15/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.6694 - accuracy: 0.5696 - val_loss: 0.6839 - val_accuracy: 0.4947\n",
            "Epoch 16/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.6728 - accuracy: 0.5596 - val_loss: 0.6850 - val_accuracy: 0.5079\n",
            "Epoch 17/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.6624 - accuracy: 0.5748 - val_loss: 0.6826 - val_accuracy: 0.5132\n",
            "Epoch 18/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.6623 - accuracy: 0.5584 - val_loss: 0.6784 - val_accuracy: 0.5105\n",
            "Epoch 19/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.6560 - accuracy: 0.5851 - val_loss: 0.6773 - val_accuracy: 0.5105\n",
            "Epoch 20/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.6560 - accuracy: 0.5783 - val_loss: 0.6830 - val_accuracy: 0.4947\n",
            "Epoch 21/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.6600 - accuracy: 0.5656 - val_loss: 0.6808 - val_accuracy: 0.5026\n",
            "Epoch 22/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.6592 - accuracy: 0.5826 - val_loss: 0.6782 - val_accuracy: 0.5053\n",
            "Epoch 23/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.6546 - accuracy: 0.5654 - val_loss: 0.6746 - val_accuracy: 0.5053\n",
            "Epoch 24/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.6590 - accuracy: 0.5352 - val_loss: 0.6699 - val_accuracy: 0.5132\n",
            "Epoch 25/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.6655 - accuracy: 0.5653 - val_loss: 0.6671 - val_accuracy: 0.5105\n",
            "Epoch 26/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.6536 - accuracy: 0.5885 - val_loss: 0.6764 - val_accuracy: 0.5132\n",
            "Epoch 27/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.6603 - accuracy: 0.5695 - val_loss: 0.6767 - val_accuracy: 0.5158\n",
            "Epoch 28/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.6342 - accuracy: 0.6001 - val_loss: 0.6764 - val_accuracy: 0.5184\n",
            "Epoch 29/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.6193 - accuracy: 0.6326 - val_loss: 0.6799 - val_accuracy: 0.5184\n",
            "Epoch 30/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.6239 - accuracy: 0.6060 - val_loss: 0.6086 - val_accuracy: 0.5974\n",
            "Epoch 31/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.6282 - accuracy: 0.6290 - val_loss: 0.6408 - val_accuracy: 0.5447\n",
            "Epoch 32/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.6162 - accuracy: 0.6356 - val_loss: 0.6711 - val_accuracy: 0.5579\n",
            "Epoch 33/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.6097 - accuracy: 0.6685 - val_loss: 0.6136 - val_accuracy: 0.5447\n",
            "Epoch 34/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.5456 - accuracy: 0.6903 - val_loss: 0.6250 - val_accuracy: 0.7184\n",
            "Epoch 35/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.5403 - accuracy: 0.6897 - val_loss: 0.6026 - val_accuracy: 0.7158\n",
            "Epoch 36/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.5265 - accuracy: 0.7128 - val_loss: 0.5933 - val_accuracy: 0.7237\n",
            "Epoch 37/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.4863 - accuracy: 0.7256 - val_loss: 0.6498 - val_accuracy: 0.6842\n",
            "Epoch 38/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.5346 - accuracy: 0.7245 - val_loss: 0.5986 - val_accuracy: 0.7395\n",
            "Epoch 39/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.5177 - accuracy: 0.7101 - val_loss: 0.5591 - val_accuracy: 0.7474\n",
            "Epoch 40/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.4785 - accuracy: 0.7640 - val_loss: 0.6325 - val_accuracy: 0.7132\n",
            "Epoch 41/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.5254 - accuracy: 0.7232 - val_loss: 0.5632 - val_accuracy: 0.7447\n",
            "Epoch 42/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.4773 - accuracy: 0.7422 - val_loss: 0.5539 - val_accuracy: 0.7605\n",
            "Epoch 43/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.4749 - accuracy: 0.7756 - val_loss: 0.5810 - val_accuracy: 0.7474\n",
            "Epoch 44/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.4923 - accuracy: 0.7588 - val_loss: 0.6173 - val_accuracy: 0.7421\n",
            "Epoch 45/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.4894 - accuracy: 0.7695 - val_loss: 0.5324 - val_accuracy: 0.7368\n",
            "Epoch 46/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.4728 - accuracy: 0.7379 - val_loss: 0.5322 - val_accuracy: 0.7763\n",
            "Epoch 47/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.4724 - accuracy: 0.7487 - val_loss: 0.5340 - val_accuracy: 0.7526\n",
            "Epoch 48/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.4561 - accuracy: 0.7755 - val_loss: 0.5195 - val_accuracy: 0.7342\n",
            "Epoch 49/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.4127 - accuracy: 0.8133 - val_loss: 0.5089 - val_accuracy: 0.8105\n",
            "Epoch 50/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.3987 - accuracy: 0.8322 - val_loss: 0.5795 - val_accuracy: 0.7500\n",
            "Epoch 51/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.4486 - accuracy: 0.7704 - val_loss: 0.5219 - val_accuracy: 0.7789\n",
            "Epoch 52/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.4143 - accuracy: 0.7993 - val_loss: 0.5923 - val_accuracy: 0.7289\n",
            "Epoch 53/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.4159 - accuracy: 0.7869 - val_loss: 0.4875 - val_accuracy: 0.8079\n",
            "Epoch 54/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.4246 - accuracy: 0.7965 - val_loss: 0.5187 - val_accuracy: 0.7868\n",
            "Epoch 55/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.3570 - accuracy: 0.8362 - val_loss: 0.4634 - val_accuracy: 0.8211\n",
            "Epoch 56/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.3715 - accuracy: 0.8358 - val_loss: 0.5040 - val_accuracy: 0.8132\n",
            "Epoch 57/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.3774 - accuracy: 0.8222 - val_loss: 0.5270 - val_accuracy: 0.7868\n",
            "Epoch 58/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.3719 - accuracy: 0.8375 - val_loss: 0.4977 - val_accuracy: 0.8211\n",
            "Epoch 59/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.3045 - accuracy: 0.8583 - val_loss: 0.4878 - val_accuracy: 0.8000\n",
            "Epoch 60/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.3436 - accuracy: 0.8470 - val_loss: 0.5151 - val_accuracy: 0.7711\n",
            "Epoch 61/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.3230 - accuracy: 0.8649 - val_loss: 0.5178 - val_accuracy: 0.7868\n",
            "Epoch 62/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.3932 - accuracy: 0.8052 - val_loss: 0.4727 - val_accuracy: 0.8237\n",
            "Epoch 63/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.3271 - accuracy: 0.8556 - val_loss: 0.4722 - val_accuracy: 0.8316\n",
            "Epoch 64/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.3265 - accuracy: 0.8533 - val_loss: 0.5439 - val_accuracy: 0.7816\n",
            "Epoch 65/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.3375 - accuracy: 0.8302 - val_loss: 0.5035 - val_accuracy: 0.7974\n",
            "Epoch 66/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.3529 - accuracy: 0.8424 - val_loss: 0.5099 - val_accuracy: 0.8184\n",
            "Epoch 67/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.3071 - accuracy: 0.8668 - val_loss: 0.5001 - val_accuracy: 0.7974\n",
            "Epoch 68/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.3342 - accuracy: 0.8292 - val_loss: 0.4998 - val_accuracy: 0.8289\n",
            "Epoch 69/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.3002 - accuracy: 0.8657 - val_loss: 0.5348 - val_accuracy: 0.7737\n",
            "Epoch 70/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.3462 - accuracy: 0.8484 - val_loss: 0.5220 - val_accuracy: 0.7974\n",
            "Epoch 71/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.3262 - accuracy: 0.8615 - val_loss: 0.4679 - val_accuracy: 0.8211\n",
            "Epoch 72/150\n",
            "48/48 [==============================] - 10s 201ms/step - loss: 0.3020 - accuracy: 0.8699 - val_loss: 0.5081 - val_accuracy: 0.8132\n",
            "Epoch 73/150\n",
            "48/48 [==============================] - 10s 201ms/step - loss: 0.3081 - accuracy: 0.8672 - val_loss: 0.5329 - val_accuracy: 0.7658\n",
            "Epoch 74/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.3641 - accuracy: 0.8353 - val_loss: 0.5194 - val_accuracy: 0.8263\n",
            "Epoch 75/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.3344 - accuracy: 0.8452 - val_loss: 0.4613 - val_accuracy: 0.8316\n",
            "Epoch 76/150\n",
            "48/48 [==============================] - 10s 201ms/step - loss: 0.3089 - accuracy: 0.8589 - val_loss: 0.4812 - val_accuracy: 0.8316\n",
            "Epoch 77/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2866 - accuracy: 0.8858 - val_loss: 0.4728 - val_accuracy: 0.8026\n",
            "Epoch 78/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2683 - accuracy: 0.8777 - val_loss: 0.5456 - val_accuracy: 0.7947\n",
            "Epoch 79/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.3127 - accuracy: 0.8630 - val_loss: 0.5000 - val_accuracy: 0.8053\n",
            "Epoch 80/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2576 - accuracy: 0.8915 - val_loss: 0.4841 - val_accuracy: 0.8184\n",
            "Epoch 81/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2753 - accuracy: 0.8710 - val_loss: 0.4857 - val_accuracy: 0.8447\n",
            "Epoch 82/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2591 - accuracy: 0.9048 - val_loss: 0.4747 - val_accuracy: 0.8289\n",
            "Epoch 83/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.2854 - accuracy: 0.8582 - val_loss: 0.5387 - val_accuracy: 0.8132\n",
            "Epoch 84/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.2482 - accuracy: 0.8976 - val_loss: 0.5014 - val_accuracy: 0.8395\n",
            "Epoch 85/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.2717 - accuracy: 0.9003 - val_loss: 0.4773 - val_accuracy: 0.8316\n",
            "Epoch 86/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2630 - accuracy: 0.8862 - val_loss: 0.4861 - val_accuracy: 0.8474\n",
            "Epoch 87/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2341 - accuracy: 0.8880 - val_loss: 0.4819 - val_accuracy: 0.8447\n",
            "Epoch 88/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2228 - accuracy: 0.9029 - val_loss: 0.4945 - val_accuracy: 0.8316\n",
            "Epoch 89/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2323 - accuracy: 0.9046 - val_loss: 0.5345 - val_accuracy: 0.8316\n",
            "Epoch 90/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.2231 - accuracy: 0.9002 - val_loss: 0.7914 - val_accuracy: 0.7526\n",
            "Epoch 91/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.2650 - accuracy: 0.8890 - val_loss: 0.4913 - val_accuracy: 0.8447\n",
            "Epoch 92/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2009 - accuracy: 0.9121 - val_loss: 0.5161 - val_accuracy: 0.8289\n",
            "Epoch 93/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.2178 - accuracy: 0.9128 - val_loss: 0.4572 - val_accuracy: 0.8474\n",
            "Epoch 94/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2266 - accuracy: 0.9053 - val_loss: 0.4519 - val_accuracy: 0.8237\n",
            "Epoch 95/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1898 - accuracy: 0.9280 - val_loss: 0.4805 - val_accuracy: 0.8263\n",
            "Epoch 96/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.2374 - accuracy: 0.9144 - val_loss: 0.4640 - val_accuracy: 0.8237\n",
            "Epoch 97/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.1929 - accuracy: 0.9216 - val_loss: 0.4954 - val_accuracy: 0.8289\n",
            "Epoch 98/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1897 - accuracy: 0.9284 - val_loss: 0.5303 - val_accuracy: 0.8316\n",
            "Epoch 99/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1886 - accuracy: 0.9154 - val_loss: 0.5696 - val_accuracy: 0.8184\n",
            "Epoch 100/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.2004 - accuracy: 0.9208 - val_loss: 0.5386 - val_accuracy: 0.8026\n",
            "Epoch 101/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.1941 - accuracy: 0.9142 - val_loss: 0.5025 - val_accuracy: 0.8316\n",
            "Epoch 102/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.1996 - accuracy: 0.9159 - val_loss: 0.5068 - val_accuracy: 0.8184\n",
            "Epoch 103/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1548 - accuracy: 0.9416 - val_loss: 0.4673 - val_accuracy: 0.8579\n",
            "Epoch 104/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.2226 - accuracy: 0.9158 - val_loss: 0.4637 - val_accuracy: 0.8368\n",
            "Epoch 105/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1921 - accuracy: 0.9237 - val_loss: 0.4868 - val_accuracy: 0.8474\n",
            "Epoch 106/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.1655 - accuracy: 0.9342 - val_loss: 0.5399 - val_accuracy: 0.8026\n",
            "Epoch 107/150\n",
            "48/48 [==============================] - 10s 201ms/step - loss: 0.2224 - accuracy: 0.9098 - val_loss: 0.5538 - val_accuracy: 0.8158\n",
            "Epoch 108/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2056 - accuracy: 0.9291 - val_loss: 0.5320 - val_accuracy: 0.8395\n",
            "Epoch 109/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.1629 - accuracy: 0.9373 - val_loss: 0.6141 - val_accuracy: 0.7789\n",
            "Epoch 110/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.2189 - accuracy: 0.9169 - val_loss: 0.5809 - val_accuracy: 0.8316\n",
            "Epoch 111/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1853 - accuracy: 0.9114 - val_loss: 0.5393 - val_accuracy: 0.8526\n",
            "Epoch 112/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1626 - accuracy: 0.9258 - val_loss: 0.5725 - val_accuracy: 0.8184\n",
            "Epoch 113/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1834 - accuracy: 0.9327 - val_loss: 0.5282 - val_accuracy: 0.8289\n",
            "Epoch 114/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1871 - accuracy: 0.9314 - val_loss: 0.5187 - val_accuracy: 0.8500\n",
            "Epoch 115/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.1350 - accuracy: 0.9447 - val_loss: 0.5515 - val_accuracy: 0.8368\n",
            "Epoch 116/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.1980 - accuracy: 0.9248 - val_loss: 0.5377 - val_accuracy: 0.8316\n",
            "Epoch 117/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.1989 - accuracy: 0.9270 - val_loss: 0.5408 - val_accuracy: 0.8447\n",
            "Epoch 118/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1910 - accuracy: 0.9228 - val_loss: 0.5060 - val_accuracy: 0.8289\n",
            "Epoch 119/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2035 - accuracy: 0.9279 - val_loss: 0.5181 - val_accuracy: 0.8395\n",
            "Epoch 120/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.1528 - accuracy: 0.9353 - val_loss: 0.5667 - val_accuracy: 0.8105\n",
            "Epoch 121/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.1584 - accuracy: 0.9429 - val_loss: 0.5106 - val_accuracy: 0.8184\n",
            "Epoch 122/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.2073 - accuracy: 0.9152 - val_loss: 0.5287 - val_accuracy: 0.8237\n",
            "Epoch 123/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1444 - accuracy: 0.9423 - val_loss: 0.4767 - val_accuracy: 0.8474\n",
            "Epoch 124/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1682 - accuracy: 0.9390 - val_loss: 0.6258 - val_accuracy: 0.8237\n",
            "Epoch 125/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.2183 - accuracy: 0.9156 - val_loss: 0.6109 - val_accuracy: 0.8026\n",
            "Epoch 126/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.1578 - accuracy: 0.9480 - val_loss: 0.5071 - val_accuracy: 0.8474\n",
            "Epoch 127/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.1357 - accuracy: 0.9564 - val_loss: 0.5102 - val_accuracy: 0.8553\n",
            "Epoch 128/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.1433 - accuracy: 0.9342 - val_loss: 0.5542 - val_accuracy: 0.8316\n",
            "Epoch 129/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1163 - accuracy: 0.9514 - val_loss: 0.5140 - val_accuracy: 0.8500\n",
            "Epoch 130/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.1807 - accuracy: 0.9244 - val_loss: 0.5088 - val_accuracy: 0.8342\n",
            "Epoch 131/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1289 - accuracy: 0.9551 - val_loss: 0.4616 - val_accuracy: 0.8605\n",
            "Epoch 132/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.1256 - accuracy: 0.9459 - val_loss: 0.4853 - val_accuracy: 0.8447\n",
            "Epoch 133/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1011 - accuracy: 0.9650 - val_loss: 0.5136 - val_accuracy: 0.8158\n",
            "Epoch 134/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1460 - accuracy: 0.9415 - val_loss: 0.5287 - val_accuracy: 0.8289\n",
            "Epoch 135/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1397 - accuracy: 0.9493 - val_loss: 0.5756 - val_accuracy: 0.7974\n",
            "Epoch 136/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1352 - accuracy: 0.9548 - val_loss: 0.5279 - val_accuracy: 0.8395\n",
            "Epoch 137/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.1212 - accuracy: 0.9511 - val_loss: 0.5421 - val_accuracy: 0.8316\n",
            "Epoch 138/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.0942 - accuracy: 0.9598 - val_loss: 0.5865 - val_accuracy: 0.8263\n",
            "Epoch 139/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1364 - accuracy: 0.9628 - val_loss: 0.5536 - val_accuracy: 0.8184\n",
            "Epoch 140/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.1305 - accuracy: 0.9499 - val_loss: 0.4994 - val_accuracy: 0.8237\n",
            "Epoch 141/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.2085 - accuracy: 0.9173 - val_loss: 0.5063 - val_accuracy: 0.8184\n",
            "Epoch 142/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.2558 - accuracy: 0.9138 - val_loss: 0.4905 - val_accuracy: 0.8316\n",
            "Epoch 143/150\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.2023 - accuracy: 0.9219 - val_loss: 0.4960 - val_accuracy: 0.8079\n",
            "Epoch 144/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1901 - accuracy: 0.9331 - val_loss: 0.4775 - val_accuracy: 0.8342\n",
            "Epoch 145/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1064 - accuracy: 0.9580 - val_loss: 0.5057 - val_accuracy: 0.8237\n",
            "Epoch 146/150\n",
            "48/48 [==============================] - 10s 205ms/step - loss: 0.1201 - accuracy: 0.9609 - val_loss: 0.4427 - val_accuracy: 0.8368\n",
            "Epoch 147/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1721 - accuracy: 0.9313 - val_loss: 0.5749 - val_accuracy: 0.8474\n",
            "Epoch 148/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1775 - accuracy: 0.9229 - val_loss: 0.5360 - val_accuracy: 0.8237\n",
            "Epoch 149/150\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.1178 - accuracy: 0.9562 - val_loss: 0.5334 - val_accuracy: 0.8105\n",
            "Epoch 150/150\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.1844 - accuracy: 0.9338 - val_loss: 0.5665 - val_accuracy: 0.8158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1k7F6C1p-bv"
      },
      "source": [
        "model.save('classifier.h5')"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}